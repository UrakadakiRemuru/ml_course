ТЕОРИЯ ВЕРОЯТНОСТИ

1. Никогда не работаем на целой выборке данных. Всегда имеем дело
с генеральной совокупностью. Г.С - всевозможные комбинации всех
объектов или наблюдений, относительно которых делаем выводы
при решении задачи.
2. Вероятность - относительная мера возможности наступления события.
3. Свойства вероятности
  3.1 Вероятность невозможного события равна нулю.
  Вероятность любого события можно представить как сумму 
  вероятностей наступления этого события и невозможного события.
  В силу аддитивности и конечности выходит, что вероятность
  невозможного события нулевая.
  3.2 P(A) <= P(B). Если событие А включается в событие В, то
  наступление А влечет наступление В.
  Это происходит в силу аддитивности и неотрицательности 
  вероятностной меры, т.к событие В помимо А может содержать и
  другие события.
  3.3 Вероятность события лежит в промежутке от 0 до 1, включая
  концы. P(X) = 1 аксиоматические предполагается. А любое событие
  входит в Х.
  3.4 P(B\A) = P(B) - P(A). Где В включает А. Вероятность В\А
  наступление события В при одновременном ненаступлении события А.
  Следует из несовместности событий. Под несовместными событиями
  понимаются события, исходы которых невозможно получить 
  одновременно. Из аддитивности вероятности: А и В\А являются
  несовместными. Их сумма равна вероятности В.
  3.5 Вероятность противоположного события к данному равна 1 - вероятность данного события
  P(!A) = 1 - P(A)
  Доказывается по аналогии. Используем все вероятностное пространство. !А и А несовместны.
  3.6 Вероятность наступления хотя бы одного из произвольных событий А или В
  P(A+B) = P(A) + P(B) - P(AB)
  Можно получить если представить как объединение двух множеств.
  P(A+B) = P(A) + P(B\AB) = P(A) + P(B) - P(AB)
4. Вероятностные распределения (дискретные)
  4.1 Дискретное равномерное распеределение.
  Случайная величина E имеет дискретное равномерное распределение, если она принимает
  конечное число значений с равными вероятностями.
  4.2 Распределение Бернулли.
  Нам заранее известна вероятность успеха.
  Случайная величина E имеет распределение Бернулли с параметром p, если E принимает значения
  0 и 1 с вероятностями 1-p и p. Случайная величина E с таким распределением равна числу 
  успехов в одном испытании схемы бернулли с вероятностью успеха E. P(E=1) = p, P(E=0) = q = 1 -p.
  4.3 Биномиальное распределение.
  Два возможных исхода: успехи и неудача. Вероятность успеха p. Серия из независимых испытаний
  с вероятностью успеха p называют испытаниями Бернулли.
  Биномиальное распределение - закон распределения случайной величины, равной количеству успехов
  в испытаниях бернулли. Случайная величина может принимать значения от 0 до n, где n - число
  испытаний. Вероятность определяется формулой Бернулли.
  P(E=k) = C_n^k p^k q^(n-k), где k - число успешных испытаний.
  С_n^k = n! / k!(n-k)!  - биномиальный коэффициент.
  4.4 Распределение Пуассона.
  Проводится n независимых испытаний, в каждом из которых случайное событие A происходит с
  вероятностью p.
  Распределение Пуассона - распределение дискретного типа случайной величины, представляющей
  собой число испытаний, произошедших за фиксированное время, при условии, что данные события
  происходят с некоторой фиксированной средней интенсивностью Л и независимо друг от друга.
  P(E=k) = Л ^ k / k! e ^ (-Л), где Л = np - мат.ожидание случайной величины (среднее кол-во
  событий за фиксированный промежуток времени.
5. Нормальное распределение. (Определения)

- Среднее значение - среднее арифметическое от значений признака
Св-ва средних значений: 
1. Алгебраическая сумма отклонений значений признака от среднего значения равна нулю
2. Если увеличить или уменьшить значения признака на одинаковое значение, то среднее значение
уменьшится или увеличится в то же количество раз.
3. Если каждое значение признака уменьшить или увеличить на одно и то же значение, то среднее
значение увеличится или уменьшится на то же значение.

- Медиана - значение, разбивающее упорядоченное по возрастанию множество ровно пополам. Если
в множестве четное количество элементов, то медиану определяем как среднее от двух значений,
разбивающих выборку пополам.

- Мода - самое частовстречающееся значение в множестве. Мод может быть несколько.
- Дисперсия - квадрат среднеквадратичного отклонения
- Среднеквадратичное отклонение: sqrt((x_i - M) ^ 2 / n)

Нормальное распределение: унимодально и симметрично
Функция плотности вероятности: f(x) = 1 / sigma / sqrt(2pi) * e^(-0.5 ((x - mu)/sigma) ^ 2)

Правило трех сигм: внтури диапазона (mu - 3sigma; mu + 3sigma) лежат 99.73% значений. 

6. Закон больших чисел.
Пусть есть бесконечная последовательность независимых одинаково распределенных СВ, для
которых существуют мат.ожидание и дисперсия. Тогда для любого eps>0:
lim(n->oo) P(sum^n_i(E_i - mu) / n) >= eps) = 0
При стремлении n к бесконечности среднее арифметическое случайных величин мало отличается от
мат.ожидания. Вероятность отклонения от мат.ожидания стремится к нулю при стремлении
размера выборки к бесконечности.

Следствие: Среднее по нашей выборке, достаточно близко к настоящему среднему и достаточно
хорошо его описывает.

В реальности тяжело гарантировать стремление n к бесконечности. Поэтому на практике ЦПТ.

7. Центральная предельная теорема.

Пусть задана бесконечная последовательность независимых случайных величин, для которых
существуют конечные мат.ожидание mu и дисперсия sigma^2.

lim(n->oo) sqrt(n) (<E> - mu) / sigma = N(0, 1) - нормальное распределение mu = 0, sigma = 1

Нормировка по среднему квадратичному отклонению и размеру выборки дает возможность
выставлять требования к размеру выборки. Это позволяет утверждать, что при бесконечном
размере выборки нормированное среднее значение ведет себя как СВ, подчинающаяся
стандартному распределению.

8. Условная вероятность.

Вероятность наступления события A, при условии наступления события B называется условной 
вероятность и обозначается P(A|B).

Рассмотри множество элементарных исходов w события B: B э w.
Пусть вероятность наступления элементарного исхода w при условии наступления B: P(w|B) = aP(w)
Для иных элементарных исходов, не принадлежащих событию B: P(w|B) = 0.
sum_w(P(w|B)) = 1
Тогда sum_w P(w|B) = sum_w aP(w) = aP(B) = 1 => a = 1 / P(B) => P(w|B) = P(w) / P(B)

Для события А: P(A|B) = sum_w P(w|B) = P(AB) / P(B)

9. Формула Байеса.

Опр. усл. вер. P(AB) = P(A|B)P(B) = P(B|A)P(A)

Тогда: P(A|B) = P(B|A)P(A) / P(B)

Формула позволяет переставить причину и следствие.

10. Независимые события

События A и B называются независимыми, если вероятность наступления одного, не зависит от
наступления другого события.
Т.е P(A|B) = P(A), тогда: 
P(AB) = P(A|B)P(B) = P(A)P(B)

Если рассматривается произвольная совокупность независимых событий, то:
P(A_1...A_n) = P(A_1) ... P(A_n)

11. Полная вероятность.

1. P(A_i) > 0. События вообще возможны
2. A_i != A_j: P(A_iA_j) = 0 - несовместные события (не произойдут одновременно)
3. P(sum A_i) = 1 - хотя бы одно произойдет.

Набор событий А_i, хотя бы одно из которых обязательно наступит в результате испытания, т.е
P(sum (A_i)) = 1, называется полным.

Пусть имеется полный набор попарно несовместных событий А_i. Тогда для любого события B
формула полной вероятности:
P(B) = sum P(B|A_i)P(A_i)

Формула Байеса через полную вероятность: 

P(A_j|B) = P(A_j)P(B|A_j) / P(B) = P(A_j)P(B|A_j) / sum P(B|A_i)P(A_i)


Практика по задачкам:
1. Вероятность выпадения 6 решек при 10 подбрасываниях монеты.
Одно подбрасывание монеты является испытанием Бернулли, так как у нас возможно два исхода:
удача: выпадение решки
неудача: выпадение орла

События являются равновероятными, так как рассматриваем идеальную монетку.
В нашем случае p = 0.5 - вероятность выпадения решки, q = 1 - p = 1 - 0.5 = 0.5 - вероятность
выпадения орла.

Проводится 10 испытаний. Поэтому нам необходимо воспользоваться биномильным распределением.
k = 6 - число успешных испытаний, ты число выпадений решки.
n = 10 - число испытаний

Тогда P(E=6) = C_10^6 * 0.5 ^ 6 * 0.5 ^ (10 - 6), где C_10^6 = 10! / 6!(10-6)! 

2. Вероятность выпадения 6 очков 2 раза при 8 подбрасываниях кубика.
по аналогии, только p = 1 / 6, q = 1 - 1 / 6 = 5 / 6
k = 2, n = 8

3. Имеются три одинаковые урны. В первой урне находятся 5 белых и 3 черных шаров,
во второй – только белые и в третьей – только черные шары.
Наудачу выбирается одна урна и из неё наугад извлекается шар.
Какова вероятность того, что этот шар чёрный?

Решаем через полную вероятность:

P(B) = sum P(B|A_i)P(A_i)

Не забываем, что A_i должны давать нам полный набор, т.е должно
точно произойти хотя бы одно из этих событий.

В данном случае у нас имеются три урны. Так как они одинаковые,
то выбор одной из трех урн равно вероятен.

Пусть A_i, где i = {1, 2, 3} - вынемаем шар из урны с соответсвующим
индексом. P(A_i) = 1 / 3.

Все эти события возможны, их вероятность больше нуля.
Какова вероятность, что мы выберем хотя бы одну урну из трех и вынем
оттуда шар? 
P(A1 + A2 + A3) = 1

Поэтому данные события образуют полный набор.

Давайте за B обозначим событие, соответствующие вынеманимю черного
шара.

В таком случае событие P(B|A_i) будет означать следующее: 
вероятность, что мы вынем черный шар, при условии, что мы вынимаем
его из iой урны.

В нашем случае: 
1. P(B|A_1) = 3 / 8. Так как в урне всего 8 шаров:5 белых и 3 черных.
2. P(B|A_2) = 0, так как во второй урне лишь белые шары. Поэтому мы не
можем вынуть из нее черный шар никоем образом.
3. P(B|A_3) = 1, так как в третьей урне лишь черные шары, поэтому 
единственный шар, который мы можем вытащить из этой урны, черного
цвета.

В итоге подставляя в формулу полной вероятности, найдем вероятность
вытягивания черного шара из одной из урн:

P(B) = 3 / 8 * 1 / 3 + 1 / 3 * 1 = 3 / 24 + 1 / 3 = 11 / 24.

Ответ: 11 / 24. 

4. На склад поступило 2 партии изделий: первая – 8000 штук, вторая – 5000 штук. 
Средний процент нестандартных изделий в первой партии 15%, во второй – 23%. 
Наудачу взятое со склада изделие оказалось нестандартным. 
Найти вероятность того, что оно из второй партии.

Здесь явно следствие и причина поменяны местами:
Причина - принадлежность партии
Следствие - нестандартное изделие

Проще решать задачу, задавая себе такой вопрос: Какова вероятность получить нестандартное
издели, если мы случайно выбрали изделие из одной из партий.

Так как исходная задача, относительно сформулированной меняет местами причину и следствие,
воспользуемся формулой Байеса:
P(A_i|B) = P(B|A_i)P(A_i) / P(B)

A_i должны образовывать полный набор.

В нашем случае
A_i - выбрать изделие из одной из партий.

А_1 = 8000 / (5000+8000) = 8 /13, А_2 = 5 / 13. 
Оба события возможны. Они несовместны, так как одно изделие не может принадлежать 
двум партиям. И хотя бы одно из них всегда выполняется P(A_1+A_2) = P(A_1) + P(A_2) = 1

B - выбранное изделие, оказалось нестандартным.

Тогда P(B|A_i) вероятность, что выбранное изделие оказалось нестандартным, при условии, что
взяли его из iой партии.

P(B|A_1) = 0.15, P(B|A_2) = 0.23

Остается воспользоваться полной вероятностью для нахождения P(B)

P(B) = P(B|A_i)P(A_i)

Тогда: P(B) = 0.15 * 8 / 13 + 0.23 * 5 / 13

Нам необходимо найти, какова вероятность, что выбранное нестандартное издели принадлежит
второй партии, поэтому

P(A_2 | B) = P(B|A_2)P(A_2) / P(B) = 0.23 * 5 / 13 / (0.15 * 8 / 13 + 0.23 * 5 / 13) = 0.489

Ответ: 0.489

5. Электролампы изготавливаются на трех заводах. 
1-й завод производит 30% общего количества ламп, 2-й – 55%, а 3-й – остальную часть. 
Продукция 1-го завода содержит 1% бракованных ламп, 2-го – 1,5%, 3-го – 2%. 
В магазин поступает продукция всех трех заводов. Купленная лампа оказалась с браком. 
Какова вероятность того, что она произведена 2-м заводом?

Здесь снова меняются местами причина и следствие.

Причина: лампа произведена заводом
Следствие: лампа оказалась бракованной

Переформулируем: Какова вероятность выбрать бракованную лампу, если она была произведена
на одном из заводов?

Здесь тоже используем формулу Байеса

P(A_i|B) = P(B|A_i)P(A_i)/P(B)

Пусть n - общее число ламп, произведенное всеми заводами.
Тогда первый завод произвел: 0.3n
второй завод: 0.55n
третий завод: 0.15n

A_i должны образовывать полный набор.

Пусть A_i - лампа принадлежит одному из заводов.

в таком случае

P(A_1) = 0.3n/n = 0.3, P(A_2) = 0.55n/n = 0.55, P(A_3) = 0.15n/n = 0.15

Действительно. Все события возможны и они несовместны, также хотя бы одно из них выполняется,
поэтому A_i образуют полный набор.

Событие B - получение бракованной лампы.

В таком случае P(B|A_i) - Получение бракованной лампы, если она была произведена на iом заводе.

P(B|A_1) = 0.01, P(B|A_2) = 0.015, P(B|A_3) = 0.02

Остается найти полную вероятность:

P(B) = sum P(B|A_i)*P(A_i) = 0.01 * 0.3 + 0.015 * 0.55 + 0.02 * 0.15 = 0.01425

В таком случае остается воспользоваться формулой Байса: 

Необходимо найти вероятность, что бракованная лампа была получена со второго завода

P(A_2|B) = P(B|A_2)P(A_2) / P(B) = 0.015 * 0.55 / 0.01425 = 0.579

Ответ: 0.579

6. В двух урнах находится соответственно 4 и 5 белых и 6 и 3 чёрных шаров.
Из каждой урны наудачу извлекается один шар, а затем из этих двух наудачу берется один.
Какова вероятность, что это будет белый шар?

Воспользуемся полной вероятностью P(B) = sum P(B|A_i)P(A_i)

A_i - должны образовывать полный набор.

A_i - вытянуты по одному шару из двух урн.

Рассмотрим все возможные комбинации вытянутых шаров из двух урн.

A_1:​﻿ из первой урны вытащили белый шар, из второй вытащили черный шар.
A_2:﻿ из первой урны вытащили белый шар, из второй вытащили белый шар.
A_3​:﻿ из первой урны вытащили черный шар, из второй вытащили черный шар.
A_4​: из первой урны вытащили черный шар, из второй вытащили белый шар.

Цвет вынутого шара из одной урны, никак не зависит от цвета вытянутого шара из другой урны,
поэтому рассматриваемые нами события являются независимыми, поэтому: P(CD) = P(C)P(D).
Заметим, что события несовместны, так как любые из этих событий не могут произойти
одновременно.

В первой урне n1 = 4 (бел) + 6 (чер) = 10 шаров,
Во второй урне n2 = 5 (бел) + 3 (чер) = 8 шаров

P(A_1) = 4 / 10 * 3 / 8 = 12 / 80 = 3 / 20
P(A_2) = 4 / 10 * 5 / 8 = 20 / 80 = 5 / 20
P(A_3) = 6 / 10 * 3 / 8 = 18 / 80 = 4.5 / 20
P(A_4) = 6 / 10 * 5 / 8 = 30 / 80 = 7.5 / 20

Заметим, что хотя бы одно из событий мы точно получим P(A_1 + ... A_4) = 1

A_i образуют полный набор событий.

Событие В - выбрали черный шар.

P(B|A_i) - вероятность, что выбранный шар окажется черным, при условии что из двух урн,
вытащили i-ую пару шаров.

P(B|A_1) = P(B|A_4) = 1 / 2, так как есть два шара, один из них черный.
P(B|A_3) = 1, так как из двух шаров оба черных.
P(B|A_2) = 0, так как из двух шаров оба белых.

Используем формулу полной вероятности: 

P(B) = 1 / 2 * 3 / 20 + 1 * 4.5 / 20 + 1 / 2 * 7.5 / 20 = 19.5 / 40 = 39 / 80

Ответ: 39 / 80

7. Из 1000 ламп 380 принадлежат к 1 партии, 270 – ко второй партии, остальные к третьей.
В первой партии 4% брака, во второй - 3%, в третьей – 6%.
Наудачу выбирается одна лампа. 
Определить вероятность того, что выбранная лампа – бракованная.

Воспользуемся формулой полной вероятности:

P(B) = sum P(B|A_i)P(A_i)

A_i должны образовывать полный набор

A_i - принадлежность лампы к одной из партий.

P(A_1) = 380 / 1000 = 38 / 100
P(A_2) = 270 / 1000 = 27 / 100
P(A_3) = 350 / 1000 = 35 / 100

Заметим, что каждой из событий возможно. Одна лампа не может быть произведена на разных
заводах. И одно из этих событий точно произойдет. В связи с этим, A_i являются
полным набором.

B - лампа оказалась бракованной.

P(B|A_i) - вероятность выбора бракованной лампы, если она была произведена на iом заводе.

Тогда:
P(B|A_1) = 0.04, P(B|A_2) = 0.03, P(B|A_3) = 0.06

Остается определить вероятность того, что выбранная лампа оказалась бракованной.
Используем формулу полной вероятности:

P(B) = 4 / 100 * 38 / 100 + 3 / 100 * 27 / 100 + 6 / 100 * 35 / 100 = 0.0443

Ответ: 0.0443

МАТ.СТАТ

Генеральная совокупность - полный набор всевозможных данных, которые мы изучаем.
Выборка - это любое подможноство генеральной совокупности.
Статистика - любое значение, вычисленное на основе выборки, используемое для описания
генеральной совокупности. (Т.е под статистикой мы можем понимать среднее значение, среднее отклонение,
дисперсию, медиану, моду и тд)

1. Статистическая гипотеза - предположение о виде распределения и свойствах случайной величины,
которое можно подтвердить или опровергнуть применением статистических методов к данным выборки.

2. Распределение Стьюдента

Это распределение используется в t-критерии Стьюдента, для оценки статистической значимости разности
двух выборочных средних, при построении доверительного интервала для математического ожидания 
нормальной совокупности при неизвестной дисперсии, а также в линейном регрессионном анализе.

Распределение Стьюдента похоже на нормальное распределение. Характерным отличием от нормального
распределения являются более "тяжелые" концы. Т.е дисперсия у СВ, подчиняющейся распределению Стьюдента,
больше, чем у СВ с нормальным распределением.

Пусть есть n независимых нормально распределенных СВ E_i, т.е E_i имеет распределение N(0,1) - стандартное.
Норамальное распределение с mu = 0 и sigma^2 = 1.

Тогда распределение случайной величины "эта": "эта" = E_0 / sqrt(sum E_i^2 / n), - называется 
распределением Стьюдента с n степенями свободы. Обозначают t(n).

Распределение Стьюдента используют для задач с оценкой мат. ожидания нормально распределенных случайных
величинн, в условиях малого размера выборки, также для задач значимости отличия средних двух выборок.
Также используются для проверки гипотез о значимости моделей регрессии.

3. Z - преобразование

Это преобразование, позволяющее отобразить исходные данные в стандартную z-шкалу (mu=0, sigma=1), 
где на оси абсцисс будут отложены стандартные отклонения.

Т.е z_i = (x_i - M) / sqrt(D) , M - среднее по выборке, D - дисперсия по выборке

Т.е мы сдвигаем мат.ожидание в нуль, при этом ось абсцисс у нас измеряется в количестве стандартных
отклонений.

Z-преобразование позволяет стандартизировать и привести к одному виду любое нормальное распределение.


4. Статистические гипотезы

Нулевая (основная) гипотеза H_0 - гипотеза, которая принимается до тех пор, пока анализ не покажет,
что она является недействительной. Ей всегда сопутствует альтернативная гипотеза H_1, которая и 
используется в случае, если основная оказывается недействительной.

Стоит отметить, что статистические методы не позволяют доказать гипотезу, они лишь позволяют ее 
опровергнуть.


5. Статистика критеря.



alpha - вероятность ошибки опровержения верной нулевой гипотезы. 
alpha имеет название - уровень значимости.

- Ошибка первого рода - это опровержение нулевой гипотезы, когда она верна.
- Ошибка второго рода - это принятие нулевой гипотезы, когда она неверна.

alpha - уровень значимости ошибки первого рода. (С какой вероятностью мы опровергнем нулевую гипотезу,
когда она верна?)
beta - вероятность ошибки второго рода.

В статистике принято брать критерий alpha = 0.05 или 5%.

- Мощность статистического критерия - вероятность не совершить ошибку второго рода, т.е 1 - beta.

На основании чего мы будем отвергать гипотезу?

- Критическая область - область значений статистики критерия, при которых опровергается H_0.
Границами критической области являются критические значения.

Примерчик: 
Есть лекарство. До внесения изменений эффективность была 0.5. После внесения изменений эффективность 
стала 0.59. Хотим понять, это отклонение в эффективности было вызвано нашими изменениями или нет.
Т.е хотим понять это отклонение статистически значимое или нет?
Условно, у нас было 60 испытуемых.
У нас биномиальное распределение (успех: выздоровление, неудача: отсутствие выздоровления)
Было 60 испытаний бернулли (1 человек - 1 испытание).
Мы знаем распределение этой величины - биномиальное.

У нас есть уровень значимости alpha = 0.05. Наше изначальное предположение будет заключаться в том,
что наши изменения в препарате не влияют на его эффективность, т.е эффективность в 0.59 - это 
случайность. Это и есть наше H_0.
Что необходимо сделать, чтобы опровергнуть эту гипотезу? 

Нам нужно найти то количество пациентов (из общего числа испытуемых, т.е 60), которое будет критическим
для того, чтобы опровергнуть гипотезу. 
P(E>=k) = int f(x), где f(x) - это плотность вероятности.
Мы хотим найти такое значение для k, чтобы P(E>=k) = alpha = 0.05
Тогда мы получим критическое значение для опровержения гипотезы. Т.е если число выздоровевших людей
будет больше и равно k + 1 тогда мы точно можем опровергать гипотезу H_0.

Для унификации этого процесса вводят понятие p-value.

p-value - это количественная мера, позволяющая оценить, насколько данные согласуются с нулевой
гипотезой.

По большому счету, это есть вероятность попадания наблюдаемой статистики в критическую область 
(это либо правый конец графика распределения СВ для одностороннего теста или правый и левый концы 
графиков для двустороннего теста), если верна нулевая гипотеза.

Если p-value < alpha, тогда мы говорим о том, что H_0 является неверной и мы ее отвергаем.
Если p-value >= alpha, это означает, что статистика, полученная из анализируемых данных, достаточно
хорошо согласуется с нулевой гипотезой.


6. Процедура проверки гипотезы


1. Сформулировать нулевую H_0 и альтернативную H_1 гипотезы, задать уровень значимости alpha.
Как правило этот уровень 0.05, чем меньше уровнеь значимости alpha, тем выше вероятность совершить
ошибку второго рода.
2. Найти критические значения и построить критическую область.
3. Вычислить значение статистики и посмотреть, попало ли оно, в критическую область. (Вычислить p-value).
4. На основании p-value сделать вывод о H_0. (отвергнуть или нет)

7. Параметрические тесты (t-критерий Стьюдента).

Статистика имеет распределение Стьюдента. Применяется для проверки равенства средних значений в двух
выборках. Нулевая гипотеза говорит о равенстве двух средних.

Параметрический критерий предполагает, что данные выборки распределены нормально.

Задана выборка
X_m = (x_i), i=[1, m]
Она имеет нормальное распределение.

Нулевая гипотеза H_0: <X> = mu, среднее по выборке равно заданному значению среднего.
H_1: <X> != mu.

Статистика критерия: t = (<X> - mu)sqrt(m) / s - распределение стьюдента с m-1 степенью свободы

<X> - выборочное среднее. s - стандартное отклонение выборки.

Отвергаем нулевую гипотезу, если |t| > t_(alpha / 2) - критическое значение.

Сравнение двух выборочных средних при известных дисперсиях.

Заданы две выборки
X_m = (x_i), i=[1, m]
Y_n = (y_i), i=[1, n]
Они имеют нормальные распределения.

Нулевая гипотеза H_0: <X> = <Y>, средние по выборкам равны.
H_1: <X> != <Y>.

Статистика критерия: z = (<X> - <Y>) / sqrt(sigma^2_x / m + sigma^2_y/n)
z имеет стандартное нормально распределение.


Отвергаем нулевую гипотезу, если |z| > z_(alpha / 2) - критическое значение.

В случае, если значения выборок не распределяются нормально, тогда нужно использовать
непараметрические тесты)

8. Непараметрические тесты
Не работают со значениями статистик, работают с рангами значений исходной выборки.

U - Критерий Манна-Уитни.
Используется для оценки различий между двумя выборками по признаку, измеренному в количественной
или порядковой шкале. Он инвариантен по отношению к любому монотонному преобразованию шкалы измерения.

Заданы две выборки.
X_m = (x_i), i=[1, m]
Y_n = (y_i), i=[1, n]

Нулевая гипотеза: выборки имеют одинаковое распределение признака

1. Объединяем две выборки в одну общую. Сортируем их (порядок сортировки неважен)
2. Назначаем каждому элемент ранг, начиная с первого. Ранг назначается в соответствии с позицией
элемента в объединенной выборке. Если есть одинаковые элементы, то их ранг - вычисляется как среднее
между текущим рангом, который мы назначаем элементу.

Например: общая выборка Z = {15, 20, 20, 20, 25, 30, 35}
ранги                       [ 1   2   3   4   5   6   7]
Есть одинаковые элементы, а именно 20, тогда ранг для 20: (2 + 3 + 4) / 3 = 3

тогда ранги: [1, 3, 3, 3, 5, 6, 7]
3. Расчитываем статистику критерия: 

U_x = R_x - m(m+1) / 2, где R_x - сумма рангов значений, соответствующих выборке x

U_y = R_y - n(n+1) / 2, где R_y - сумма рангов значений, соответствующих выборке y

Находим минимум из этих двух значиний U = min(U_x, U_y) - cтатистика критерия.

Если U <= U_crit - отвергаем H_0.
Если U > U_crit - оставляем H_0.

9. A/B тесты.

1. Сформулировать гипотезы

H_0: между результатами A и B нет статистически значимых отличий.
H_1: между результатми A и B есть статистически значимые отличия.

2. Определить контрольную и целевую группы.

Контрольная - используют что-то старое А.
Целевая - используют что-то новое В.

Нужно четко понимать, как и по каким признакам мы формируем эти группы.
Определяем размеры эих групп.

3. Обеспечиваем равновозможные шансы просмотра новой и старой версии для пользователей.

4. Определить уровень статистической значимости (уровень риска при ошибках первого рода.

5. Определение минимального размера выборки

6. Определяем время проведения.

Определение размера и времени зависит от:
1. Минимального размера эффекта, который хотим измерить
2. Допустимые вероятности ошибок первого и второго рода

Расчитываем мощность выбранного статистического критерия по этим данным.

Собираем данные и при помощи статистических методов проводим их анализ, позволяющий опровергнуть 
H_0.

ML

1. Машинное обучение - наука о разработке алгоритмов и статистических моделей, которые
компьютерные системы используют для выполнения задач без явных инструкций, полагаясь
на шаблоны и логические выводы.

Мы на курсе в основном будем работать с табличными данными.

Типы значений в табличных данных.

Количественные
Бинарные 
Номинальные - множество значений
Порядковые - версионность и тд

Типы целевой переменной:
1. Качественная бинарная - решение задачи бинароной классификации.
2. Количественная непрерывная - задачи регресии (числа).
3. Количестенная дискретная - многоклассовая классификация (распознование рукописных цифр).
4. Количественная полиномиальная - случай многоклассовой классификации, когда один объект
может принадлежать нескольким классам.

Классическое машинное обучение делят на два блока: 
1. Обучение с учителем
2. Обучение без учителя

2. Постановка задачи обучения с учителем 

Это задачи, при решении которых мы используем подготовленные наборы данных, с уже указанной
целевой переменной - это может быть как ограниченный набор целочисленных меток (задача
классификации), так и вещественные числа (задача регрессии).

Отличия этих двух задач заключается в виде целевой переменной, как следствие, отличие
в функционале ошибок, который мы минимизируем.

1. Задача классификации

Мы работаем с табличными данными, поэтому наш набор данных представляет из себя матрицу
с информацией по признакам каждого объекта и целевой переменной.
Целевая переменная - информация о том, к какому классу относится каждый объект.

Пусть X - множество описаний объектов, Y - конечное множество меток классов (виды классов).
Существует неизвестная целевая зависимость - отображение y^*: X -> Y, значения которой
известны только на объектах конечной обучающей выборки X_m = {(x_i, y_i)}.
Требуется построить алгоритм f: X -> Y, способный классифицировать произвольный объект x
из множества X.

В простейшем случае тип целевой переменной - бинарный (т.е 0 или 1). Это бинарная
классификация. Если классов больше чем 2, тогда используется многоклассовая постановка
задачи классификации. (Н: распознование рукописного ввода чисел. Тут будет 10 классов - 0,1..9)

2. Задача регрессии или регрессия.

Здесь пытаемся спрогнозировать временной ряд

Пусть X - множество описаний объектов, Y - множество вещественных чисел. Существует неизвестная
целевая зависимость - отображение y^*: X -> Y, значения которой известны лишь на обучающей выборке
X_m = {(x_i, y_i)}. Требуется построить алгоритм f: X -> Y, способный классифицировать произвольный
объект x из X.

3. Решение задач.

Семейство алгоритмов G={g: X->Y}.

Подбирается семейство функций g(x, tetta), где tetta - оптимальный набор параметров моедли.

Как выбрать лучший алгоритм? Т.е как выбрать g?

Свести задачу к задаче оптимизации. Оптимизации подлежит функционал ошибки, который будет
минимизироваться.

Вводится функция потерь L(y, y^*), которая характеризует величину отклонения ответа модели f(x) от
фактического ответа на произвольном объекте x из X.

Эмперический риск - функционал качества, характеризующий ошибку алгоритма g на анализируемой выборке
X_m:

Q(g, X_m) = 1 / m sum_i L(g(x_i), y(x_i))

Суть метода минимизации эмперического риска: найти алгоритм, минимизирующий функционал эмперического
риска:

g = argmin Q(g, X_m)

Функция потерь для классификации считается как количество неверно классифицированных объектов:

L(y,y^*) = [y!= y^*]

Функция потерь для регресии является квадратичной функцией потерь:

L(y,y^*) = (y - y^*)^2

Итого, что нам нужно делать?

Есть функция потерь, суммируем ее по всем значениям обучающей выборки, получаем эмперический
функционал. Этот функционал будем минимизировать по параметру предсказательной модели g(x, tetta).
Т.е ищем параметр tetta, который приведет эмперический риск к минимум.

Обучение с учителем - это оптимизация (минимизация) эмперического риска. Для решения задачи можно
использовать в случае регрессии метод наименьших квадратов. Так как там тоже используется разность
квадратов, то мы получаем возможность продифференцировать по tetta и приравнять к нулю, т.е найти
минимум.

4. Выбор модели

По большому счету это первый этап решения задачи.
Мы подготавливаем выборку: заполняем пропуски, убираем аномальные значения.
И строим алгоритм на подготовленных данных.


Нам не подходит вариант с простым запоминанием данных, так как модель не занимается поиском 
закономерности. Нам же нужно понять, какие закономерности в данных имеются.

Поэтому после обучения модели проводят тесты на других данных из ГС. Это необходимо для оценки
обобщающей способности - способности выявлять закономерности в данных, которые присущи ГС.

Поэтому изначально выборку делят на обучающую и тестовую. Обучающую используют для обучения модели,
а на тестовой уже считают метрики и делают выводы.

Такой подход позволяет выявить модели, в которых произошла генерализация. Т.е те модели, которые
действительно выявили какую-то закономерность в данных и теперь они могут определять эту
закономерность на ранее неизвестных данных.

5. Переобучение

Это второй этап. Мы должны понять, насколько адекватно модель обобщает данные. Т.е модельке
нужно скормить новый набор данных и посмотреть на метрики.

Под переобучением мы понимаем избыточное подстроение алгоритмов под данные.

С увеличением сложности модели ошибка на обучающей выборке падает. Однако стоит учитывать, что
в таком случае модель может плохо справляться с обобщением данных, так как выученные данные из
обучающей выборки могут не так хорошо отражать генеральную совокупность.

Поэтому резонно задаться вопросом: когда стоит остановить обучение модели?

На этапе оценки качества модели, важно понять, нашли ли мы необходимое отображение в пространство
целевой переменной или же мы просто очень хорошо подогнали алгоритм g под обучающий набор данных.

Это нужно оценивать по тестовым данным. Если точность модели на тестовых данных сильно ниже 
точности модели на обучающих данных - это значит, что модель является переобученной.

6. Метрики

Для регресси: 

Абсолютные ошибки.

1. MSE (mean squared error) - квадратичное отклонение истинного и предсказанного значений
MSE(y, y*) = 1 / n sum (y - y*)^2

Размерность данных и ошибки отличаются в квадрат раз. Дурно реагирует на выбросы, поэтому лучше
использовать RMSE

2. RMSE - квадратный корень из MSE.

Недостатки: мы не можем указать границы для хороших и плохих алгоритмов, т.к эти ошибки неограничены
сверху.

Рассмотрим ошибки, устраняющие этот недостаток.

3. R^2 = 1 - MSE(y, y*) / D(y), где D = sum (y - <y>)^2 / n

4. MAE
Исключает квадрат, но теперь мы не можем дифференцировать функционал

MAE(y,y*) = 1 / n sum |y - y*|

Вывод по абсолютным:
Преимущества: можем хорошо подогнать модельные данные под исходные
Недостатки: мы не можем сравнивать две модели при одинаковой метрике. 

Относительные ошибки.

1. MAPE

MAPE(y, y*) = 1 / n sum |y - y*| / |y|

Недостаток: деление на нуль.

2. SMAPE

решает проблему деления на нуль

SMAPE(y,y*) = 1 / n sum 2|y-y*|/(y + y*)

Эти метри плохо работают с временным рядами и не учитывают сезонность.

3. WAPE

решает проблему для временных рядов

WAPE(y, y*) = sum |y-y*| / sum |y|

Оптимизация метрик происходит с помощью метода наименьших квадратов. Там где модуль: возвращаем в
точке нуль значение производной в 0.

Для классификации. 

Сначала рассмотрим бинарный классификатор, при этом 1 - это положительный класс, -1 - другой класс.

1. Точность

Доля объектов, на которых модель дает правильные ответы.

Accuracy(y,y*) = 1 / n sum I[y = y*]

Недостаток: некорректные результаты для несбалансированных выборок.

TP - true positive: модель верно отнесла объект к положительному классу.
TN - true negative: модель верно отнесла объект к другому классу.
FP - false positive: модель неверно отнесла объект к положительному классу.
FN - false negative: модель неверно отнесла объект к другому классу.

В таких терминах Accurcy = (TP + TN) / (TP + TN + FP + FN)
Количество верных классификаций модели, ко всем классификациям модели.

2. Precision (точность) + Recall (полнота)

Precision = TP / (TP + FP)
Отношение правильных предсказаний ко всем правильным предсказаниям.
Precision показывает насколько мы можем доверять классификатору в случае, если он показывает 1 для
объекта. (Вероятность того, что объект действительно относится к положительному классу)


Recall = TP / (TP + FN)

Показывает долю верных срабатываний к общему размеру положительного класса.

Вывод: 
Если мы хотим минимизировать ложные срабатывания, то нужно иметь максимальный precision.
Если мы хотим минимизировать ложные пропуски, то нужно иметь максимальный recall.

Недостатки: тут две метрики на которые нужно смотреть одновременно. Это плохо для оптимизации.

3. F1 - гармоническое среднее recall и precision.

F1 = Recall * Precision / (Recall + Precision)

Можно добавить вес, который будет учитывать важность метрики.

F1 = (beta^2 + 1) Recall * Precision / (Recall + beta^2 * Precision), beta = [0, 1]

4. PR-curve 

График в координатах Precision(Recall).

Хорош при работе с несбалансированными данными.

Чем выше кривая, тем лучше модель.

Недостаток: нужно расчитывать две метрики и делать выводы из двух значений.

5. ROC-AUC

Specificity(FPR) - доля отрицательных примеров, неверно отнесенных к положительному классу,
ко всем .

FPR = FP / (FP + TN)

Sensivity (TPR) - то же самое, что и полнота.

График в координатах TPR(1 - FPR)

Площадь под кривой - метрика качетсва: чем ближе к единице, тем точнее модель.


7. kNN - метод ближайших k соседей

Это метрический алгоритм. 

Метрический алгоритм - это подход, при котором мы используем некоторый функционал метрики 
расстояния для объектов.

Использую функционал метрики, мы можем вычислять соседей рассматриваемого, т.е наиболее близкие
точки к этому объекту. 

Идейно: мы говорим рассматриваемой точке, чтобы она посмотрела на соседей вокруг себя,
посмотрела на тот класс, который доминирует в этой области (наибольшее количество соседей
принадлежат этому классу). К этому классу и будет относится рассматриваемая точка.

Метрика - мера расстояния.
1. Неотрицательная
2. Если она равна нулю, то объекты являются одним объектом.
3. Неравенство треугольника |a + b| < |a| + |b|

Гипотеза компактности:

Если метрика расстояния между двумя объектами введена удачно, то похожие объекты гораздо чаще
лежат в одном классе, чем в разных.

Метрика задается как функция расстояние - метрическая функция от пары объектов, которая в
соответсвие каждой паре объектов ставит неотрицательное число, являющееся расстоянием между ними.

Различные метрики: 
1. Минковского

r = (sum |a_i - b_i|^p)^(1/p)

2. Евклидова (p=2)

r = sqrt(sum (a_i - b_i)^2)

3. Манхэттенская (p=1)

r = sum |a_i - b_i|

4. Чебышева (p=oo)

r = max |a_i - b_i|

5. Считающее расстояние

В данном случае расстояние равно количеству отличающихся компонент двух векторов.

6. Косинусное расстояние

r = arccos((a . b) / |a||b|)

используется для измерения схожести между текстами. чем больше совпадений по словам, тем больше
косинус.

Алгоритм метода:

1. Выбрать объект из выборки
2. Вычислить расстояние от выбранного объекта до всех оставшихся в выборке объектов.
3. Отсортировать массив расстояний в порядке возрастания.
4. Отобрать k объектов из нового массива.
5. Посчитать вес w(i, x) - функция от объекта и индекса в отсортированном массиве.
6. Усреднить в каждом классе значение весов.
7. Присвоить объекту класс, для которого оценка максимально близка.